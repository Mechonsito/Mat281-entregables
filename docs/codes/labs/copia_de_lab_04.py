# -*- coding: utf-8 -*-
"""Copia de lab_04.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GcmJh0o0KkXGVkHjLAcPSEEShuU3nE92

<a href="https://colab.research.google.com/github/fralfaro/MAT281/blob/main/docs/labs/lab_04.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

# MAT281 - Laboratorio N°04

**Objetivo**: Aplicar técnicas intermedias y avanzadas de análisis de datos con pandas utilizando un caso real: el Índice de Libertad de Prensa. Este laboratorio incluye operaciones de limpieza, transformación, combinación de datos, y análisis exploratorio usando `merge`, `groupby`, `concat` y otras funciones fundamentales.

**Descripción del Dataset**

El presente conjunto de datos está orientado al análisis del **Índice de Libertad de Prensa**, una métrica internacional que evalúa el nivel de libertad del que gozan periodistas y medios de comunicación en distintos países. Este índice es recopilado anualmente por la organización **Reporteros sin Fronteras**.

La base de datos contempla observaciones por país y año, e incluye tanto el valor del índice como el ranking correspondiente. A menor puntaje en el índice, mayor nivel de libertad de prensa.

**Diccionario de variables**

| Variable     | Clase    | Descripción                                                                          |
| ------------ | -------- | ------------------------------------------------------------------------------------ |
| `codigo_iso` | carácter | Código ISO 3166-1 alfa-3 que representa a cada país.                                 |
| `pais`       | carácter | Nombre oficial del país.                                                             |
| `anio`       | entero   | Año en que se registró la medición del índice.                                       |
| `indice`     | numérico | Valor numérico del Índice de Libertad de Prensa (menor valor indica mayor libertad). |
| `ranking`    | entero   | Posición relativa del país en el ranking mundial de libertad de prensa.              |


**Fuente original y adaptación pedagógica**

* **Fuente original**: [Reporteros sin Fronteras](https://www.rsf-es.org/), recopilado y publicado a través del portal del [Banco Mundial](https://tcdata360.worldbank.org/indicators/h3f86901f?country=BRA&indicator=32416&viz=line_chart&years=2001,2019).
* **Adaptación educativa**: Los archivos han sido modificados intencionalmente para incorporar desafíos técnicos que permiten aplicar los contenidos abordados en clases, tales como limpieza de datos, normalización, detección de duplicados, y combinación de fuentes.


**Descripción de los archivos disponibles**

* **`libertad_prensa_codigo.csv`**: Contiene los pares `codigo_iso` y `pais`. Incluye intencionalmente un código ISO con dos nombres distintos de país para efectos de limpieza y validación de datos.

* **`libertad_prensa_01.csv`**: Contiene registros de los años **anteriores a 2010**. Incluye las variables `PAIS`, `ANIO`, `INDICE`, y `RANKING` con nombres de columna en **mayúsculas**.

* **`libertad_prensa_02.csv`**: Contiene registros de los años **desde 2010 en adelante**. Estructura similar al archivo anterior, con nombres de columna también en **mayúsculas**.
"""

import numpy as np
import pandas as pd

# lectura de datos
archivos_anio = [
    'https://raw.githubusercontent.com/fralfaro/MAT281/main/docs/labs/data/libertad_prensa_01.csv',
    'https://raw.githubusercontent.com/fralfaro/MAT281/main/docs/labs/data/libertad_prensa_02.csv'
 ]
df_codigos = pd.read_csv('https://raw.githubusercontent.com/fralfaro/MAT281/main/docs/labs/data/libertad_prensa_codigo.csv')

"""

### 1. Consolidación y limpieza de datos

A partir de los archivos disponibles, realice los siguientes pasos:

**a)** Cree un DataFrame llamado `df_anio` que consolide la información proveniente de los archivos **`libertad_prensa_01.csv`** y **`libertad_prensa_02.csv`**, correspondientes a distintas ventanas de tiempo. Recuerde que ambos archivos tienen nombres de columnas en mayúscula, por lo que debe normalizarlas a **minúscula** para asegurar consistencia.

**b)** Explore el archivo **`libertad_prensa_codigo.csv`** e identifique el código ISO que aparece asociado a dos nombres de país distintos. Elimine el registro que corresponda a un valor incorrecto o inconsistente, conservando solo el que considere válido.

**c)** Una vez preparados los archivos, cree un nuevo DataFrame llamado `df` que combine `df_anio` con `df_codigos`, utilizando la columna `codigo_iso` como clave. Asegúrese de realizar una unión que conserve únicamente los registros que tengan coincidencia en ambas fuentes.

> **Sugerencia**:
>
> * Para unir los archivos por filas (años), utilice la función `pd.concat([...])`.
> * Para combinar información por columnas (variables), utilice `pd.merge(...)` especificando `on='codigo_iso'`.

"""

# a)

df_01 = pd.read_csv(archivos_anio[0])
df_02 = pd.read_csv(archivos_anio[1])

df_01.columns = df_01.columns.str.lower()
df_02.columns = df_02.columns.str.lower() # Aqui hacemos que todas las columnas ahora solo esten en minusculas

df_anio = pd.concat([df_01, df_02], ignore_index=True)
df_anio.head(10)

# b)
ISO=df_codigos.groupby('codigo_iso') #agrupamos la tabla por codigos
numpaisesxiso=ISO['pais'].nunique() #contamos la cantidad de paises distintos que aparecen en cada codigo
codigos_duplicados=numpaisesxiso[numpaisesxiso>1].index.to_list() #creamos una tabla con los codigos que tienen mas de 1 pais asociado
df_codigos.loc[df_codigos['codigo_iso'].isin(codigos_duplicados)] #buscamos en el df de codigos donde aparece el codigo duplicado para elegir cual borrar

#notamos que el codigo que esta malo es el de la fila 180
df_codigos=df_codigos.drop(180) #eliminamos la fila

#c)
df=pd.merge(df_anio, df_codigos, on='codigo_iso', how='inner') #combinamos los dataframes manteniendo solo las filas que coinciden los codigos ISO
df.head(10)

"""

### 2. Exploración inicial del conjunto de datos

Una vez que hayas consolidado el DataFrame final `df`, realiza un análisis exploratorio básico respondiendo las siguientes preguntas:

#### **Estructura del DataFrame**

* ¿Cuántas **filas (observaciones)** contiene el conjunto de datos?
* ¿Cuántas **columnas** tiene el DataFrame?
* ¿Cuáles son los **nombres de las columnas**?
* ¿Qué **tipo de datos** tiene cada columna?
* ¿Hay columnas con un tipo de dato inesperado (por ejemplo, fechas como strings)?

#### **Resumen estadístico**

* Genera un resumen estadístico del conjunto de datos con `.describe()`.
  ¿Qué observas sobre los valores de `indice` y `ranking`?
* ¿Qué valores mínimo, máximo y promedio tiene la columna `indice`?
* ¿Qué países presentan los valores extremos en `indice` y `ranking`?

#### **Datos faltantes**

* ¿Cuántos valores nulos hay en cada columna?
* ¿Qué proporción de observaciones tienen valores faltantes?
* ¿Hay columnas con más del 30% de datos faltantes?

#### **Unicidad y duplicados**

* ¿Cuántos países distintos (`pais`) hay en el DataFrame?
* ¿Cuántos años distintos (`anio`) hay representados?
* ¿Existen filas duplicadas (exactamente iguales)? ¿Cuántas?

#### **Validación cruzada de columnas**

* ¿Hay inconsistencias entre el país (`pais`) y su código (`codigo_iso`)?
  (por ejemplo, un mismo código ISO asociado a más de un país)

> **Sugerencia**: Apoya tu análisis con funciones como `.info()`, `.nunique()`, `.isnull().sum()`, `.duplicated()`, `.value_counts()`, entre otras.



    """

# FIXME
df.info()

#asi notamos que df tiene 3060 filas y 5 columnas
#las columnas se llaman codigo_iso, anio, indice, ranking y pais
#las columas codigo_iso y pais tienen datos tipo object, la columna anio tiene datos tipo int64 y las columnas indice y ranking tienen datos tipo float 64
#bajo mi analisis no veo que hayan datos inesperados en la tabla ya que cada tipo de dato es consistente con lo esperado segun la columna

df.describe()

#no entiendo que tengo que observar acerca del indice y ranking que me piden, puedo ver que tienen una cantidad de datos distintas y que el ranking es mayor al indice pero no se si esto es util

max_indice = df['indice'].max()
min_indice = df['indice'].min()
mean_indice = df['indice'].mean()

print("Máximo de la columna 'indice':", max_indice)
print("Mínimo de la columna 'indice':", min_indice)
print("Promedio de la columna 'indice':", mean_indice)

max_rank=df['ranking'].max()
min_rank=df['ranking'].min()

print("\nPaís(es) con el valor máximo de indice:")
display(df[df['indice'] == max_indice])

print("\nPaís(es) con el valor mínimo de indice:")
display(df[df['indice'] == min_indice])

print("\nPaís(es) con el valor máximo de ranking:")
display(df[df['ranking'] == max_rank])

print("\nPaís(es) con el valor mínimo de ranking:")
display(df[df['ranking'] == min_rank])

# Contamos los valores nulos por columna
nulos = df.isnull().sum()
proporcion_nulos = nulos / len(df)

print("Valores nulos por columna:")
print(nulos)

print("\nProporción de valores nulos por columna:")
print(proporcion_nulos)
filas_duplicadas=df.duplicated().sum()
print("\nCantidad de filas duplicadas:", filas_duplicadas)

#podemos notar que no hay columnas con mas del 30% de datos faltantes

paises_distintos = df['pais'].nunique()
print("Cantidad de países distintos:", paises_distintos)
cantidad_años=df['anio'].nunique()
print("Cantidad de años distintos:", cantidad_años)
iso_distintos=df['codigo_iso'].nunique()
print("Cantidad de códigos ISO distintos:", iso_distintos)

#podemos observar que hay 1 iso mas que paises, por lo que vamos a aplicar nuevamente lo hecho en 1 para encontrar la inconsistencia

grupopais=df.groupby('pais') #agrupamos la tabla por paises
numisosxpais=grupopais['codigo_iso'].nunique() #contamos la cantidad de paises distintos que aparecen en cada codigo
codigos_duplicados=numisosxpais[numisosxpais>1].index.to_list() #creamos una tabla con los codigos que tienen mas de 1 pais asociado
df.loc[df['pais'].isin(codigos_duplicados)] #buscamos en el df de codigos donde aparece el codigo duplicado para elegir cual borrar

#aqui podemos notar que nigeria tiene 2 codigos Iso asociados, lo que es una inconsistencia

"""


### 3. Comparación regional: países latinoamericanos

En esta sección se busca identificar cuáles son los países de América Latina que han presentado los valores extremos del **Índice de Libertad de Prensa** en cada año observado.

> Recuerda que un menor puntaje en `indice` implica mayor libertad de prensa.

#### **Tareas:**

**a)** Utilizando un ciclo `for`, recorre cada año del conjunto de datos filtrado por países latinoamericanos, y determina para cada año:

* El país con el menor valor de `indice` (mayor libertad de prensa).
* El país con el mayor valor de `indice` (menor libertad de prensa).

**b)** Resuelve la misma tarea del punto anterior utilizando un enfoque vectorizado con `groupby`, sin usar ciclos explícitos.



#### **Lista de países latinoamericanos considerada:**

```python
america = ['ARG', 'ATG', 'BLZ', 'BOL', 'BRA', 'CAN', 'CHL', 'COL', 'CRI',
           'CUB', 'DOM', 'ECU', 'GRD', 'GTM', 'GUY', 'HND', 'HTI', 'JAM',
           'MEX', 'NIC', 'PAN', 'PER', 'PRY', 'SLV', 'SUR', 'TTO', 'URY',
           'USA', 'VEN']
```

> Puedes usar esta lista para filtrar el DataFrame final por la columna `codigo_iso`.

"""

# respuesta
america = ['ARG', 'ATG', 'BLZ', 'BOL', 'BRA', 'CAN', 'CHL', 'COL', 'CRI',
       'CUB', 'DOM', 'ECU', 'GRD', 'GTM', 'GUY', 'HND', 'HTI', 'JAM',
       'MEX', 'NIC', 'PAN', 'PER', 'PRY', 'SLV', 'SUR', 'TTO', 'URY',
       'USA', 'VEN']

df_america =  df.loc[df['codigo_iso'].isin(america)] # FIX ME
for año in df_america['anio'].unique(): #Recorremos los años de manera unica (no pasamos 2 veces por el mismo año)
    df_año = df_america[df_america['anio'] == año] #creamos un df por cada año para que el analisis sea mas sencillo
    if df_año['indice'].isnull().sum()!= df_año.shape[0]: #verificamos que haya informacion de cada año
        indice_minimo = df_año['indice'].max()
        indice_maximo = df_año['indice'].min()
        maximo = df_año[df_año['indice']== indice_maximo]
        minimo = df_año[df_año['indice']== indice_minimo] #extraemos la informacion
        print("El año", año, "el pais con mejor indice fue")
        display(maximo)
        print("El año", año, "el pais con peor indice fue")
        display(minimo)
    else:
      print("no hay informacion para el año",año)

maximo=df_america[df_america['indice']==df_america.groupby('anio')['indice'].transform('min')]
minimo=df_america[df_america['indice']==df_america.groupby('anio')['indice'].transform('max')]
print("El pais con mejor indice por año fue")
display(maximo)
print("El pais con peor indice por año fue")
display(minimo)

"""### 4. Análisis anual del índice por país

En esta sección se busca analizar la evolución del **índice máximo** de libertad de prensa alcanzado por cada país a lo largo del tiempo.

#### **Tarea principal:**

* Construye una tabla dinámica (`pivot_table`) donde las **filas** correspondan a los países, las **columnas** a los años (`anio`) y los **valores** sean el `indice` máximo alcanzado por cada país en ese año.
* Asegúrate de reemplazar los valores nulos resultantes con `0`.

> **Hint**: Puedes utilizar el parámetro `fill_value=0` en `pd.pivot_table(...)`.



#### **Preguntas adicionales:**

**a)** ¿Qué país tiene el mayor valor de `indice` en toda la tabla resultante? ¿Y cuál tiene el menor (distinto de cero)?
**b)** ¿Qué años presentan en promedio los valores de `indice` más altos? ¿Y los más bajos?

> (Pista: usa `.mean(axis=0)` sobre la tabla pivot)

**c)** ¿Qué país muestra mayor **variabilidad** (diferencia entre su máximo y mínimo `indice` a lo largo del tiempo)?

> (Pista: aplica `.max(axis=1) - .min(axis=1)`)

**d)** ¿Existen países con índice constante a lo largo de todos los años registrados? ¿Cuáles?

**e)** ¿Qué países no tienen ningún dato (es decir, quedaron con todos los valores igual a 0)? ¿Podrías explicar por qué?




"""

pivot_df=df_america.pivot_table(index='pais', columns='anio', values='indice', fill_value=0)
pivot_df

# Calcular el valor máximo de toda la tabla dinámica
max_valor_tabla = pivot_df.max().max() # Calcula el maximo de cada columna, y luego el maximo de esos maximos

min_valor_tabla = pivot_df[pivot_df > 0].min().min() # Filtra los 0s y luego encuentra el minimo
ubicacion_max = pivot_df[pivot_df == max_valor_tabla].stack().index.tolist()
ubicacion_min = pivot_df[pivot_df == min_valor_tabla].stack().index.tolist()
print(f"El valor máximo ({max_valor_tabla}) se encuentra en:", ubicacion_max)
print(f"El valor mínimo (distinto de 0) ({min_valor_tabla}) se encuentra en:", ubicacion_min)

# Calcular el promedio del indice para cada año (promedio de las columnas)
promedio_por_año = pivot_df.mean(axis=0)
promedio_maximo = promedio_por_año.idxmax()
promedio_minimo = promedio_por_año.idxmin()
print("El año con mayor indice promedio es:", promedio_maximo, "con un promedio de:", promedio_por_año.max())
print("El año con menor indice promedio es:", promedio_minimo,"con un promedio de:", promedio_por_año.min())

variabilidad_por_pais = pivot_df.max(axis=1) - pivot_df.min(axis=1)
pais_max_variabilidad = variabilidad_por_pais.idxmax()
print("El pais con mayor variabilidad es:", pais_max_variabilidad)

min_por_pais = pivot_df.min(axis=1)
max_por_pais = pivot_df.max(axis=1)
min_por_pais==max_por_pais

#no existen paises con indices cosntantes

no_data = pivot_df[pivot_df.eq(0).all(axis=1)]
paises_sin_datos = no_data.index.tolist()
print("Países sin datos:", paises_sin_datos)